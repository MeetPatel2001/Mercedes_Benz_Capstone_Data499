{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5537e0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryku\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aryku\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0cab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "categorical_vars = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8']\n",
    "train = train.drop(columns=categorical_vars)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "test_data, train_data = train[:800], train[800:]\n",
    "\n",
    "# Separate input features (X) and target variable (y) for training dataset\n",
    "X_train = train_data.drop(columns=['y', 'ID'])  # Drop target variable and non-predictive variables\n",
    "y_train = train_data['y']  # Target variable\n",
    "\n",
    "# Separate input features (X) and target variable (y) for testing dataset\n",
    "X_test = test_data.drop(columns=['y', 'ID'])  # Drop target variable and non-predictive variables\n",
    "y_test = test_data['y']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd11ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70aad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features: 368\n"
     ]
    }
   ],
   "source": [
    "features_train = X_train\n",
    "input_dim = features_train.shape[1]\n",
    "print(\"Number of input features:\", input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcd5a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aryku\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\aryku\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                23616     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24145 (94.32 KB)\n",
      "Trainable params: 24145 (94.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Add first hidden layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c1877f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28fcfdf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\aryku\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\aryku\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "86/86 [==============================] - 1s 4ms/step - loss: 7730.9424 - accuracy: 0.0000e+00 - val_loss: 2858.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 780.5728 - accuracy: 0.0000e+00 - val_loss: 232.6961 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 224.2402 - accuracy: 0.0000e+00 - val_loss: 161.5693 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 169.0923 - accuracy: 0.0000e+00 - val_loss: 112.7398 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 130.8737 - accuracy: 0.0000e+00 - val_loss: 83.1112 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 108.7428 - accuracy: 0.0000e+00 - val_loss: 70.8788 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 97.5667 - accuracy: 0.0000e+00 - val_loss: 60.6835 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 91.6681 - accuracy: 0.0000e+00 - val_loss: 55.7235 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 88.3156 - accuracy: 0.0000e+00 - val_loss: 59.4426 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 85.9902 - accuracy: 0.0000e+00 - val_loss: 58.0596 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 84.5121 - accuracy: 0.0000e+00 - val_loss: 56.2230 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 83.6433 - accuracy: 0.0000e+00 - val_loss: 57.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 82.9940 - accuracy: 0.0000e+00 - val_loss: 55.7653 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 82.0821 - accuracy: 0.0000e+00 - val_loss: 51.5397 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 81.5751 - accuracy: 0.0000e+00 - val_loss: 55.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 80.9955 - accuracy: 0.0000e+00 - val_loss: 50.3910 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 80.7046 - accuracy: 0.0000e+00 - val_loss: 53.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 80.3637 - accuracy: 0.0000e+00 - val_loss: 60.6849 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 79.8637 - accuracy: 0.0000e+00 - val_loss: 53.4919 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 79.4793 - accuracy: 0.0000e+00 - val_loss: 52.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 79.4200 - accuracy: 0.0000e+00 - val_loss: 50.2665 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 79.3749 - accuracy: 0.0000e+00 - val_loss: 54.3321 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 79.1036 - accuracy: 0.0000e+00 - val_loss: 59.3774 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 78.7396 - accuracy: 0.0000e+00 - val_loss: 50.5337 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 78.0925 - accuracy: 0.0000e+00 - val_loss: 57.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 77.9891 - accuracy: 0.0000e+00 - val_loss: 49.3756 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 78.4680 - accuracy: 0.0000e+00 - val_loss: 51.3568 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 77.3238 - accuracy: 0.0000e+00 - val_loss: 53.9299 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 77.3617 - accuracy: 0.0000e+00 - val_loss: 52.6293 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 77.3551 - accuracy: 0.0000e+00 - val_loss: 48.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 77.6203 - accuracy: 0.0000e+00 - val_loss: 52.6634 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 76.7707 - accuracy: 0.0000e+00 - val_loss: 49.1755 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 76.6972 - accuracy: 0.0000e+00 - val_loss: 55.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 76.8579 - accuracy: 0.0000e+00 - val_loss: 60.9999 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 76.3572 - accuracy: 0.0000e+00 - val_loss: 53.5654 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 75.9677 - accuracy: 0.0000e+00 - val_loss: 52.3856 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 75.8666 - accuracy: 0.0000e+00 - val_loss: 52.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 75.7429 - accuracy: 0.0000e+00 - val_loss: 50.8422 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 75.6319 - accuracy: 0.0000e+00 - val_loss: 50.1879 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 75.0941 - accuracy: 0.0000e+00 - val_loss: 50.5740 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 75.0422 - accuracy: 0.0000e+00 - val_loss: 61.3029 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 75.2367 - accuracy: 0.0000e+00 - val_loss: 53.9638 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 74.5837 - accuracy: 0.0000e+00 - val_loss: 54.3995 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 74.1916 - accuracy: 0.0000e+00 - val_loss: 53.3996 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 74.3311 - accuracy: 0.0000e+00 - val_loss: 52.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 74.1771 - accuracy: 0.0000e+00 - val_loss: 53.6783 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 73.9938 - accuracy: 0.0000e+00 - val_loss: 50.6455 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 73.6071 - accuracy: 0.0000e+00 - val_loss: 51.5358 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 73.2402 - accuracy: 0.0000e+00 - val_loss: 60.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 73.4935 - accuracy: 0.0000e+00 - val_loss: 54.0545 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 73.1372 - accuracy: 0.0000e+00 - val_loss: 60.0752 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 73.1230 - accuracy: 0.0000e+00 - val_loss: 57.5736 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 72.7429 - accuracy: 0.0000e+00 - val_loss: 51.7692 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 72.4726 - accuracy: 0.0000e+00 - val_loss: 54.2772 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 72.1764 - accuracy: 0.0000e+00 - val_loss: 75.9808 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 72.6075 - accuracy: 0.0000e+00 - val_loss: 61.2554 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 72.1950 - accuracy: 0.0000e+00 - val_loss: 52.6544 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 71.2196 - accuracy: 0.0000e+00 - val_loss: 51.2028 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 71.1992 - accuracy: 0.0000e+00 - val_loss: 54.0833 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 70.8680 - accuracy: 0.0000e+00 - val_loss: 58.1564 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 71.1471 - accuracy: 0.0000e+00 - val_loss: 63.0958 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 70.5406 - accuracy: 0.0000e+00 - val_loss: 54.4398 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 70.3586 - accuracy: 0.0000e+00 - val_loss: 64.3078 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 70.3149 - accuracy: 0.0000e+00 - val_loss: 52.7803 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 69.6885 - accuracy: 0.0000e+00 - val_loss: 55.8839 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 69.6435 - accuracy: 0.0000e+00 - val_loss: 58.5309 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 69.2474 - accuracy: 0.0000e+00 - val_loss: 59.7445 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 69.4322 - accuracy: 0.0000e+00 - val_loss: 53.2381 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 68.7621 - accuracy: 0.0000e+00 - val_loss: 60.1904 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 68.3806 - accuracy: 0.0000e+00 - val_loss: 55.4938 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 68.4069 - accuracy: 0.0000e+00 - val_loss: 57.7495 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 68.1987 - accuracy: 0.0000e+00 - val_loss: 55.0668 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 67.5691 - accuracy: 0.0000e+00 - val_loss: 54.9606 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 67.7645 - accuracy: 0.0000e+00 - val_loss: 57.0899 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 67.5654 - accuracy: 0.0000e+00 - val_loss: 59.2278 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 66.9147 - accuracy: 0.0000e+00 - val_loss: 58.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 66.6503 - accuracy: 0.0000e+00 - val_loss: 55.9346 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 66.6921 - accuracy: 0.0000e+00 - val_loss: 53.7300 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 66.2935 - accuracy: 0.0000e+00 - val_loss: 54.6280 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 66.1071 - accuracy: 0.0000e+00 - val_loss: 56.1129 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 65.4981 - accuracy: 0.0000e+00 - val_loss: 58.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 65.7144 - accuracy: 0.0000e+00 - val_loss: 61.8298 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 65.5017 - accuracy: 0.0000e+00 - val_loss: 80.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 65.2330 - accuracy: 0.0000e+00 - val_loss: 60.7643 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 64.7856 - accuracy: 0.0000e+00 - val_loss: 65.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 64.9813 - accuracy: 0.0000e+00 - val_loss: 71.5183 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 64.6675 - accuracy: 0.0000e+00 - val_loss: 71.5665 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 63.9123 - accuracy: 0.0000e+00 - val_loss: 57.8028 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 63.9372 - accuracy: 0.0000e+00 - val_loss: 57.5925 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 63.4844 - accuracy: 0.0000e+00 - val_loss: 61.2531 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 63.0450 - accuracy: 0.0000e+00 - val_loss: 59.1644 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 63.3614 - accuracy: 0.0000e+00 - val_loss: 57.8058 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 62.7044 - accuracy: 0.0000e+00 - val_loss: 57.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 62.5195 - accuracy: 0.0000e+00 - val_loss: 61.1993 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 62.4121 - accuracy: 0.0000e+00 - val_loss: 58.8389 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 62.5530 - accuracy: 0.0000e+00 - val_loss: 69.0832 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 61.9456 - accuracy: 0.0000e+00 - val_loss: 57.7791 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 62.1431 - accuracy: 0.0000e+00 - val_loss: 58.6322 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 61.4160 - accuracy: 0.0000e+00 - val_loss: 61.4891 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 61.4952 - accuracy: 0.0000e+00 - val_loss: 56.9432 - val_accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 83.5209 - accuracy: 0.0000e+00\n",
      "Test Loss: [83.52092742919922, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsFElEQVR4nO3de5hU1Znv8e+7d1X1lZvQKtIoOIMSLnKxQxzNBaMnYRKPOEZGfMwRohMSxxOjOZOoOTOjMx6eeObxZDLMiT7HMUacGBkmGZUkaqKcGDKjR8VbFJVIhEgHwk2BBvpWVe/5Y69uiupquoEuGrp/n+epp3at2mvvtasvb63LXsvcHRERkYOJ+rsAIiJy7FOwEBGRHilYiIhIjxQsRESkRwoWIiLSIwULERHpUaqcBzezG4E/Axx4DfgcUA38CzAO2AD8qbu/H/a/BbgGyAHXu/tPQ/rZwP1AFfAY8GXvYczvqFGjfNy4cX19SSIiA9qLL7643d3ritOtXPdZmNkY4N+BSe7ebGbLSf7RTwLec/c7zOxmYIS732Rmk4CHgFnAKcBTwBnunjOz54EvA/8vHGOJuz9+sPM3NDT46tWry3JtIiIDlZm96O4NxenlboZKAVVmliKpUWwC5gJLw/tLgUvC9lxgmbu3uvt6YB0wy8xGA0Pd/dlQm3igII+IiBwFZQsW7v474E7gXWAzsMvdfwac5O6bwz6bgRNDljHAxoJDNIa0MWG7OL0LM1tkZqvNbPW2bdv68nJERAa1sgULMxtBUlsYT9KsVGNmnz1YlhJpfpD0ronu97h7g7s31NV1aXITEZHDVM4O7guB9e6+DcDM/g04F9hiZqPdfXNoYtoa9m8ExhbkrydptmoM28XpInIMaG9vp7GxkZaWlv4uihyCyspK6uvrSafTvdq/nMHiXeAcM6sGmoELgNXAXmABcEd4fjTsvwL4vpl9k6QmMgF4PnRwN5nZOcBzwFXAP5ax3CJyCBobGxkyZAjjxo3DrFRDgBxr3J0dO3bQ2NjI+PHje5WnbMHC3Z8zsx8ALwFZ4GXgHqAWWG5m15AElHlh/zVhxNQbYf/r3D0XDnct+4fOPh4eInIMaGlpUaA4zpgZI0eO5FD6dst6n4W73wrcWpTcSlLLKLX/YmBxifTVwJQ+L6CI9AkFiuPPof7MdAd3kaXPbOBHr6pLRESkkIJFkQef+y2Pvba5v4shIr20Y8cOpk+fzvTp0zn55JMZM2ZM5+u2traD5l29ejXXX399j+c499xz+6SsTz/9NBdddFGfHOtoK2sz1PEojiLac1o9UOR4MXLkSF555RUAbrvtNmpra/mLv/iLzvez2SypVOl/dQ0NDTQ0dLlZuYtnnnmmT8p6PFPNokgqMnL5fH8XQ0SOwMKFC/nKV77C+eefz0033cTzzz/Pueeey4wZMzj33HNZu3YtcOA3/dtuu42rr76a2bNnc/rpp7NkyZLO49XW1nbuP3v2bC677DImTpzIlVdeSceUSY899hgTJ07kwx/+MNdff/0h1SAeeughpk6dypQpU7jpppsAyOVyLFy4kClTpjB16lT+/u//HoAlS5YwadIkzjrrLObPn3/kH1YvqWZRJBUb2bxqFiKH429+tIY3Nu3u02NOOmUot/7nyYec79e//jVPPfUUcRyze/duVq1aRSqV4qmnnuLrX/86P/zhD7vkeeutt/j5z39OU1MTZ555Jtdee22X+xBefvll1qxZwymnnMJ5553Hf/zHf9DQ0MAXvvAFVq1axfjx47niiit6Xc5NmzZx00038eKLLzJixAg+8YlP8MgjjzB27Fh+97vf8frrrwOwc+dOAO644w7Wr19PRUVFZ9rRoJpFkVRkZNUMJXLcmzdvHnEcA7Br1y7mzZvHlClTuPHGG1mzZk3JPJ/+9KepqKhg1KhRnHjiiWzZsqXLPrNmzaK+vp4oipg+fTobNmzgrbfe4vTTT++8Z+FQgsULL7zA7NmzqaurI5VKceWVV7Jq1SpOP/103nnnHb70pS/xxBNPMHToUADOOussrrzySr73ve9127xWDqpZFElFETnVLEQOy+HUAMqlpqamc/uv/uqvOP/883n44YfZsGEDs2fPLpmnoqKiczuOY7LZbK/2OZLZu7vLO2LECF599VV++tOf8u1vf5vly5dz33338ZOf/IRVq1axYsUKbr/9dtasWXNUgoZqFkVSsdGuPguRAWXXrl2MGZPMP3r//ff3+fEnTpzIO++8w4YNGwD4l3/5l17n/dCHPsQvfvELtm/fTi6X46GHHuJjH/sY27dvJ5/P85nPfIbbb7+dl156iXw+z8aNGzn//PP5u7/7O3bu3MmePXv6/HpKUc2iSByZahYiA8zXvvY1FixYwDe/+U0+/vGP9/nxq6qquOuuu5gzZw6jRo1i1qxZ3e67cuVK6uv3T3f3r//6r3zjG9/g/PPPx9351Kc+xdy5c3n11Vf53Oc+Rz58ef3GN75BLpfjs5/9LLt27cLdufHGGxk+fHifX08pZVv8qL8d7uJHf7Z0NZt2NvPYlz9ShlKJDDxvvvkmH/jAB/q7GP1uz5491NbW4u5cd911TJgwgRtvvLG/i3VQpX52/bX40XEnFRlZNUOJyCH6p3/6J6ZPn87kyZPZtWsXX/jCF/q7SH1KzVBFNHRWRA7HjTfeeMzXJI6EahZFNHRWRKQrBYsisYbOioh0oWBRJB2rz0JEpJiCRZFYzVAiIl0oWBRJx5E6uEWOI7Nnz+anP/3pAWnf+ta3+PM///OD5ukYWv+pT32q5BxLt912G3feeedBz/3II4/wxhtvdL7+67/+a5566qlDKH1px+JU5mULFmZ2ppm9UvDYbWY3mNkJZvakmb0dnkcU5LnFzNaZ2Voz+2RB+tlm9lp4b4mVcVmupGahZiiR48UVV1zBsmXLDkhbtmxZr+dneuyxxw77xrbiYPG3f/u3XHjhhYd1rGNd2YKFu6919+nuPh04G9gHPAzcDKx09wnAyvAaM5sEzAcmA3OAu8wsDoe7G1gETAiPOeUqd3KfhWoWIseLyy67jB//+Me0trYCsGHDBjZt2sSHP/xhrr32WhoaGpg8eTK33lq8wnNi3LhxbN++HYDFixdz5plncuGFF3ZOYw7JPRQf/OAHmTZtGp/5zGfYt28fzzzzDCtWrOCrX/0q06dP5ze/+Q0LFy7kBz/4AZDcqT1jxgymTp3K1Vdf3Vm+cePGceuttzJz5kymTp3KW2+91etr7c+pzI/WfRYXAL9x99+a2VxgdkhfCjwN3ATMBZa5eyuw3szWAbPMbAMw1N2fBTCzB4BLgMfLUdBUrOk+RA7b4zfD71/r22OePBX++I5u3x45ciSzZs3iiSeeYO7cuSxbtozLL78cM2Px4sWccMIJ5HI5LrjgAn71q19x1llnlTzOiy++yLJly3j55ZfJZrPMnDmTs88+G4BLL72Uz3/+8wD85V/+Jd/5znf40pe+xMUXX8xFF13EZZdddsCxWlpaWLhwIStXruSMM87gqquu4u677+aGG24AYNSoUbz00kvcdddd3Hnnndx77709fgz9PZX50eqzmA88FLZPcvfNAOH5xJA+BthYkKcxpI0J28XpXZjZIjNbbWart23bdlgFjaOkz2KgToMiMhAVNkUVNkEtX76cmTNnMmPGDNasWXNAk1GxX/7yl/zJn/wJ1dXVDB06lIsvvrjzvddff52PfOQjTJ06lQcffLDbKc47rF27lvHjx3PGGWcAsGDBAlatWtX5/qWXXgrA2Wef3Tn5YE/6eyrzstcszCwDXAzc0tOuJdL8IOldE93vAe6BZG6oQyhmp3SUnC6Xd1Jx2bpGRAamg9QAyumSSy7hK1/5Ci+99BLNzc3MnDmT9evXc+edd/LCCy8wYsQIFi5cSEtLy0GP01136MKFC3nkkUeYNm0a999/P08//fRBj9PTl82Oac67mwb9UI55tKYyPxo1iz8GXnL3jlVEtpjZaIDwvDWkNwJjC/LVA5tCen2J9LKIQ4BQv4XI8aO2tpbZs2dz9dVXd9Yqdu/eTU1NDcOGDWPLli08/vjBW64/+tGP8vDDD9Pc3ExTUxM/+tGPOt9rampi9OjRtLe38+CDD3amDxkyhKampi7HmjhxIhs2bGDdunUA/PM//zMf+9jHjuga+3sq86PRZ3EF+5ugAFYAC4A7wvOjBenfN7NvAqeQdGQ/7+45M2sys3OA54CrgH8sV2FTkYKFyPHoiiuu4NJLL+1sjpo2bRozZsxg8uTJnH766Zx33nkHzT9z5kwuv/xypk+fzmmnncZHPrJ/5unbb7+dD33oQ5x22mlMnTq1M0DMnz+fz3/+8yxZsqSzYxugsrKS7373u8ybN49sNssHP/hBvvjFLx7S9RxrU5mXdYpyM6sm6Yc43d13hbSRwHLgVOBdYJ67vxfe++/A1UAWuMHdHw/pDcD9QBVJx/aXvIeCH+4U5ff9+3r+9sdv8Opff4Jh1emeM4gMcpqi/Ph1KFOUl7Vm4e77gJFFaTtIRkeV2n8xsLhE+mpgSjnKWKyjn0Kr5YmI7Kc7uIukouQj0fBZEZH9FCyKdPRZtOsubpFe01Dz48+h/swULIrEBUNnRaRnlZWV7NixQwHjOOLu7Nixg8rKyl7n0Up5RVIaOitySOrr62lsbORwb4SV/lFZWXnAaKueKFgU6eiz0DTlIr2TTqcZP358fxdDykzNUEX21yzUZyEi0kHBokjnTXmqWYiIdFKwKBLrDm4RkS4ULIqkY91nISJSTMGiSGfNQvdZiIh0UrAoktbQWRGRLhQsisQdQ2c1GkpEpJOCRRGNhhIR6UrBokjHfRbq4BYR2U/BokjnRIIKFiIinRQsiuyfolx9FiIiHRQsisSdU5SrZiEi0qGswcLMhpvZD8zsLTN708z+yMxOMLMnzezt8DyiYP9bzGydma01s08WpJ9tZq+F95aYmZWrzOqzEBHpqtw1i38AnnD3icA04E3gZmClu08AVobXmNkkYD4wGZgD3GVmcTjO3cAiYEJ4zClXgTtnnVWwEBHpVLZgYWZDgY8C3wFw9zZ33wnMBZaG3ZYCl4TtucAyd2919/XAOmCWmY0Ghrr7s56srvJAQZ4+l9Id3CIiXZSzZnE6sA34rpm9bGb3mlkNcJK7bwYIzyeG/ccAGwvyN4a0MWG7OL0LM1tkZqvNbPXhLsSiZigRka7KGSxSwEzgbnefAewlNDl1o1Q/hB8kvWui+z3u3uDuDXV1dYdaXmB/M5Q6uEVE9itnsGgEGt39ufD6ByTBY0toWiI8by3Yf2xB/npgU0ivL5FeFvvX4FYzlIhIh7IFC3f/PbDRzM4MSRcAbwArgAUhbQHwaNheAcw3swozG0/Skf18aKpqMrNzwiioqwry9LmU1rMQEemi3Gtwfwl40MwywDvA50gC1HIzuwZ4F5gH4O5rzGw5SUDJAte5ey4c51rgfqAKeDw8yiKKjMg0N5SISKGyBgt3fwVoKPHWBd3svxhYXCJ9NTClTwt3EKk4Us1CRKSA7uAuIRWZhs6KiBRQsCghjkw1CxGRAgoWJaTjSPdZiIgUULAoIalZqBlKRKSDgkUJ6cg0GkpEpICCRQlxrD4LEZFCChYlpCINnRURKaRgUUIqMk33ISJSQMGihDgyTSQoIlJAwaIEDZ0VETmQgkUJSc1CzVAiIh0ULEpI+ixUsxAR6aBgUUJKQ2dFRA6gYFFCKoo0kaCISAEFixJSsZqhREQKKViUkNLQWRGRA5Q1WJjZBjN7zcxeMbPVIe0EM3vSzN4OzyMK9r/FzNaZ2Voz+2RB+tnhOOvMbElYXrVsYnVwi4gc4GjULM539+nu3rFi3s3ASnefAKwMrzGzScB8YDIwB7jLzOKQ525gEcm63BPC+2WTrJSnPgsRkQ790Qw1F1gatpcClxSkL3P3VndfD6wDZpnZaGCouz/r7g48UJCnLFJa/EhE5ADlDhYO/MzMXjSzRSHtJHffDBCeTwzpY4CNBXkbQ9qYsF2cXjbJaCgFCxGRDqkyH/88d99kZicCT5rZWwfZt1Q/hB8kvesBkoC0CODUU0891LJ2SmnxIxGRA5S1ZuHum8LzVuBhYBawJTQtEZ63ht0bgbEF2euBTSG9vkR6qfPd4+4N7t5QV1d32OWONXRWROQAZQsWZlZjZkM6toFPAK8DK4AFYbcFwKNhewUw38wqzGw8SUf286GpqsnMzgmjoK4qyFMWafVZiIgcoJzNUCcBD4dRring++7+hJm9ACw3s2uAd4F5AO6+xsyWA28AWeA6d8+FY10L3A9UAY+HR9nE6rMQETlA2YKFu78DTCuRvgO4oJs8i4HFJdJXA1P6uozdScfqsxARKaQ7uEuII1PNQkSkgIJFCR33WSS3dYiIiIJFCak4+VjUxy0iklCwKCGOkls7tFqeiEhCwaKEdJwEC91rISKSULAoIY6Sj0Wd3CIiCQWLElKhGUrDZ0VEEgoWJaTUDCUicgAFixI6ahbtChYiIoCCRUmp0GeRU5+FiAigYFFSRzNUu/osREQABYuSOu6zUJ+FiEhCwaKElIbOiogcQMGiBA2dFRE5kIJFCR19FloASUQk0atgEVa9i8L2GWZ2sZmly1u0/qNmKBGRA/W2ZrEKqDSzMcBK4HMkK9cNSLGaoUREDtDbYGHuvg+4FPhHd/8TYFKvMprFZvaymf04vD7BzJ40s7fD84iCfW8xs3VmttbMPlmQfraZvRbeWxLW4i4bTSQoInKgXgcLM/sj4ErgJyGtt0uyfhl4s+D1zcBKd59AUku5OZxgEjAfmAzMAe4yszjkuRtYBEwIjzm9PPdh6axZqBlKRATofbC4AbgFeNjd15jZ6cDPe8pkZvXAp4F7C5LnAkvD9lLgkoL0Ze7e6u7rgXXALDMbDQx192c9WbrugYI8ZZEOix+pg1tEJNGr2oG7/wL4BUDo6N7u7tf3Iuu3gK8BQwrSTnL3zeG4m83sxJA+Bvh/Bfs1hrT2sF2c3oWZLSKpgXDqqaf2onil7a9ZqM9CRAR6Pxrq+2Y21MxqgDeAtWb21R7yXARsdfcXe1mWUv0QfpD0ronu97h7g7s31NXV9fK0Xe2/z0I1CxER6H0z1CR3303S/PMYcCrwX3rIcx5wsZltAJYBHzez7wFbQtMS4Xlr2L8RGFuQvx7YFNLrS6SXTcca3OrgFhFJ9DZYpMN9FZcAj7p7O918u+/g7re4e727jyPpuP6/7v5ZYAWwIOy2AHg0bK8A5ptZhZmNJ+nIfj40WTWZ2TlhFNRVBXnKIqU1uEVEDtDbEU3/B9gAvAqsMrPTgN2Hec47gOVmdg3wLjAPIHScLydp5soC17l7LuS5luS+jirg8fAoGy1+JCJyoN52cC8BlhQk/dbMzu/tSdz9aeDpsL0DuKCb/RYDi0ukrwam9PZ8RyrW4kciIgfobQf3MDP7ppmtDo//BdSUuWz9Zv/iR2qGEhGB3vdZ3Ac0AX8aHruB75arUP1NEwmKiByot30Wf+Dunyl4/Tdm9koZynNM0NBZEZED9bZm0WxmH+54YWbnAc3lKVL/62yGUrAQEQF6X7P4IvCAmQ0Lr99n//DXAUdDZ0VEDtTb0VCvAtPMbGh4vdvMbgB+Vcay9ZsoMsxUsxAR6XBIK+W5++5wJzfAV8pQnmNGOorUZyEiEhzJsqplXVOiv8WRaSJBEZHgSILFgP7anYpNNQsRkeCgfRZm1kTpoGAkU28MWKnItPiRiEhw0GDh7kMO9v5AFqvPQkSk05E0Qw1o6djI5dVnISICChbditUMJSLSScGiG+lYzVAiIh0ULLoRR0ZWzVAiIoCCRbc0GkpEZD8Fi26kYtN0HyIiQdmChZlVmtnzZvaqma0xs78J6SeY2ZNm9nZ4HlGQ5xYzW2dma83skwXpZ5vZa+G9JWEt7rKKo0gr5YmIBOWsWbQCH3f3acB0YI6ZnQPcDKx09wnAyvAaM5sEzAcmA3OAu8wsDse6G1gETAiPOWUsNwDpSENnRUQ6lC1YeGJPeJkODwfmAktD+lLgkrA9F1jm7q3uvh5YB8wys9HAUHd/1t0deKAgT9nEkdGuPgsREaDMfRZmFocV9bYCT7r7c8BJ7r4ZIDyfGHYfA2wsyN4Y0saE7eL0Uudb1LFO+LZt246o7OqzEBHZr6zBwt1z7j4dqCepJUw5yO6l+iH8IOmlznePuze4e0NdXd0hl7dQKoo066yISNDblfKOiLvvNLOnSfoatpjZaHffHJqYtobdGoGxBdnqgU0hvb5Eenns+h1YlAydVc1CRAQo72ioOjMbHrargAuBt4AV7F+SdQHwaNheAcw3swozG0/Skf18aKpqMrNzwiioqwry9L1/vgSeuFnNUCIiBcpZsxgNLA0jmiJgubv/2MyeBZab2TXAu8A8AHdfY2bLgTeALHCdu+fCsa4F7ieZFv3x8CiPTA207yMVRVqDW0QkKFuwcPdfATNKpO8ALugmz2JgcYn01cDB+jv6TqYW2vYSV6pmISLSQXdwF0tXQ9teUrGGzoqIdFCwKJapSYJFpJqFiEgHBYtiHcFCU5SLiHRSsCiWqYH2vWHorDq4RURAwaKrULOIDXLqsxARARQsukpXQz5LZZSjXTULERFAwaKrTC0AlbSog1tEJFCwKJapAaDaW9TBLSISKFgUy1QDUOktuKPahYgIChZddTRDeQuARkSJiKBg0VVohqr0ZgCyGhElIqJg0UU6aYaqyIdgoWYoEREFiy5CM1RFaIZSn4WIiIJFV6EZqrNmoWnKRUQULLoIo6EyaoYSEemkYFEsndQsMvkwGkod3CIiChZdpDIQpcnk9wEaOisiAuVdg3usmf3czN40szVm9uWQfoKZPWlmb4fnEQV5bjGzdWa21sw+WZB+tpm9Ft5bEtbiLp9MDem8OrhFRDqUs2aRBf6bu38AOAe4zswmATcDK919ArAyvCa8Nx+YDMwB7grrdwPcDSwCJoTHnDKWGzK1pHNJzUKr5YmIlDFYuPtmd38pbDcBbwJjgLnA0rDbUuCSsD0XWObure6+HlgHzDKz0cBQd3/W3R14oCBPeWSqSWWTDm7VLEREjlKfhZmNA2YAzwEnuftmSAIKcGLYbQywsSBbY0gbE7aL00udZ5GZrTaz1du2bTv8AmdqSIc+C01TLiJyFIKFmdUCPwRucPfdB9u1RJofJL1rovs97t7g7g11dXWHXtgOmVpS2SRYqGYhIlLmYGFmaZJA8aC7/1tI3hKalgjPW0N6IzC2IHs9sCmk15dIL590NXFWc0OJiHQo52goA74DvOnu3yx4awWwIGwvAB4tSJ9vZhVmNp6kI/v50FTVZGbnhGNeVZCnPDI1xFkNnRUR6ZAq47HPA/4L8JqZvRLSvg7cASw3s2uAd4F5AO6+xsyWA2+QjKS6zt1zId+1wP1AFfB4eJTPAcFCNQsRkbIFC3f/d0r3NwBc0E2excDiEumrgSl9V7oeFAYLNUOJiOgO7pIyNUTt+wAnp2YoEREFi5LS1ZhnyZBVM5SICAoWpYU1LappUTOUiAgKFqWFNS2qaVXNQkQEBYvSwpoW1daixY9ERFCwKC00Q9XQopqFiAgKFqV1NENZq6b7EBFBwaK0dGiGooV2NUOJiChYlNQ5Gko1CxERULAoraAZSn0WIiIKFqWF0VA1us9CRARQsCgtXdjBrT4LEREFi1JSGYgz1FoL7WqGEhFRsOhWuppaDZ0VEQEULLqXqaXGWjV0VkQEBYvuZaqpUc1CRAQo77Kq95nZVjN7vSDtBDN70szeDs8jCt67xczWmdlaM/tkQfrZZvZaeG9JWFq1/DI11Jim+xARgfLWLO4H5hSl3QysdPcJwMrwGjObBMwHJoc8d5lZHPLcDSwiWZN7QoljlkemlipaNZGgiAhlDBbuvgp4ryh5LrA0bC8FLilIX+bure6+HlgHzDKz0cBQd3/W3R14oCBPeaWrk/UsVLMQETnqfRYnuftmgPB8YkgfA2ws2K8xpI0J28XpJZnZIjNbbWart23bdmQlzdRo8SMRkeBY6eAu1Q/hB0kvyd3vcfcGd2+oq6s7shJlaqjS3FAiIsDRDxZbQtMS4XlrSG8ExhbsVw9sCun1JdLLL1NDlbeQ1R3cIiJHPVisABaE7QXAowXp882swszGk3RkPx+aqprM7JwwCuqqgjzllamhimayWQULEZFUuQ5sZg8Bs4FRZtYI3ArcASw3s2uAd4F5AO6+xsyWA28AWeA6d8+FQ11LMrKqCng8PMovU0NMHvJtR+V0IiLHsrIFC3e/opu3Luhm/8XA4hLpq4EpfVi03gmTCaay+476qUVEjjXHSgf3sSesabFr187+LYeIyDFAwaI7YU2L7e+/z859aooSkcFNwaI7YWnVGlp4ZePO/i2LiEg/U7DoTsHSqgoWIjLYKVh0J500Q00YbgoWIjLoKVh0JzRDTTwh4tWNO0mmphIRGZwULLoTmqH+YHjE+/va+e0ODaEVkcFLwaI7YTTUaUOSGoWaokRkMFOw6E64Ka+uIktVOlawEJFBTcGiO6kMxBni7D6m1g/jZQULERnEFCwOJl0NbXuZMXY4b27aTWs213MeEZEBSMHiYDK10LaX6WOH05bL88am3f1dIhGRfqFgcTCZpGYxbexwQJ3cIjJ4KVgcTKYG9mxh9JA0Jw6pYPWG93W/hYgMSgoWB3PaefDus9i9F/DZ+q385LXNXHr3Mzzx+u+13KqIDCo2UL8pNzQ0+OrVq4/sIO7w+g/hZ38JTZtZf/If83fvf5THd53KmOHVfGrqycyZcjIzxo4gikotFy4icnwxsxfdvaFLuoJFL7Q2wao74YXvQFsTu4edyY+j8/n+1nGsydUzrLqCSaOHMmn0UM44aQgnDq2gbkgFI2sqqK1MUZ2OFUxE5Lhw3AcLM5sD/AMQA/e6+x0H279Pg0WH1j3w2r/C6u/A718DoC09jPUVZ/Lb9hH8urmWzblhbPdh7PAhvM8Q9nolzVQQZyqpifPUprJUx3lSUYTFMVGUgiiFRynMIuIIYnNicyAibzFEMTlLY1FMZGBmGBCTwzGIYgwwA8MwA9yppJnq3F5S3k5zqpaWqAaP0gX7Jsfqwp2Mt5HJN5PyNlriGtqiGizqOK+T8RZycYa8pTqy0PGrZKGMkUFU6viA4xT+6kVh/87yuJMKZcjkmom9nda4hpZULfmosrP8Heejc3v/iy5nDuUxdzL5fVS1vwcYLfEQWlM1uKW6fI5WfIKuhyw49/58kWepyu4mk9tDNqqkNa6lPaoizrdSkd9HOt8CFpGzFHlLkY0ryUaV4TO2cGxnSOtmRu55m5F73wZ3dleOpqnyFPZV1NGSGkZ7qpYoipNzmh3wueBOnG8j9jbS3kqcbSaVaybKZ2lPD6EtM5z2VDUV7bupbHufTLaJtswwmitG0Z4aAmZEkByDLFG+nSifJfIchgN58lGG9lQNubgKcCpye8lk9xCZk42ryMdVuMXEnsW8PSmWpclHafJRjFmEARF5zHNYPkvk7Vg+R+RZ8Fz43TDcYjxO41GSH0vhFnf+fDr+Low8ls9iniciSxSOFeXbkkeujUzzFqp3/4bq3evBjH1D/4DmYX9IW+VI4lwLqVwLcbaZqH0Pcfse4lzL/h+4pWmtOZn22jG0V9VhUceCo47l2ojzrUT5dogi3NIQp8Bi8kRgUefnakZyvbk2onwrZhEepchHKaL2faRadpBq3gEG2aqTyNXUkUvXgnu4xhyRtxPl2zHyeKqKfKoKT1Xxh2NOJooPr5fhuA4WZhYDvwb+E9AIvABc4e5vdJenLMGi0M6N8Nv/gA2/TAJH0+/xPVvDH1F5tJOi1SqIyJPxNlIk9320kqHZKskRkyZL7FkqaU3WEC/SRoo8UecjS0yOGDcj7VkqaCVDO1HRdbSTYg/VZGinhubO9H1U0kQNeYyYPClyxORIkyVFFgNyBedqCWdwoII2KmkjJk8bKVpJ4xg1NFNDM6kS5Qdo95gsMcmfzIF/EDmizocn/4Jwwt84DjhD2UeVdV3QKusRloTfzmPlD8iZvNuR2vF5toWrtrBHhixD7dDnEsu5sY9KgPD55UhZ6c+gOE8eIxc+izQ5MmSpsPZDLkOHVk8l12K9u7co5xa+4Bx97R4DScA51DLs8moMDuvndSxr+VojldVDDitvd8GibGtw97FZwDp3fwfAzJYBc4Fug0XZDR8Lw+fDtPmdSZZrh73bYO/25Hnfe9C+F9r2QbYFUhXJI86Er+I5yOfA85DPJo9QU8CiZJ+O9Fwb6fZm0tnkGympSkhXgTsVbXuoaNsL+XaIw/HTlVA5HCqHQZxOmtJadpFp25uc1z05dz6b5PN8csxUBaSqkmHD6erkWK1NpJvfY0TzzuScFUOSe1CyLVQ376S6ZRfgodxxkidOQ5QCM9Id15hrY2h7c/JZeD45VqoqyZdthVxbkp6pDeeo2f8cZ6B1N7TsIt3atP+Ynmf/d2nf/1nm2sPr8EiqCMnXuYqhUHsi1NQlaS27oGUXqVzbAbWIqOP4ng/Vpo5jhW+IOBW5dsi14bl2sAi3CCwmV3UCVJ+AVwyFbDPWshtr24unK/F0DZ6pSY6Va4d8G9beDK17qGrbk1xJnMGjFG1Dx5Crm0yu7gNYnCba3Ui0ayO2dys0vwf73qOibS/uecjnktF6cQUep2mOM3iqcv8jHX6mUQpadmLNO6FtD145jHzVSDwzFGt5n2jfNqK928CMtriCfJTG4wxEaTzUgt2SYBzlWrC2PURtTbjF5DNDyGWGABFkm4myzZDP4iEvJN+mLdeG53PJZwqhhpwcG0vhccd54vCxOx5qHpZrh1xrqD1ksXw2hPgIN3BLhZ9FTD6KcUuRtzSeyuBRhnycIVs1ipZhf0C2ciTukGreStXOt4lbd5GLK8nFVeTiSvKZIeQzteRTlbiH341sC+m9m8ns20x63zYo+FKTjzKdD/c8lm8P5cyFR77z64jjuKXIhf2BpJaQz5JPV9FWMZK2ihOSmn7LNjLNW4mz+5LfsdDqkI/S5C2FY8S5lvBoZkJFdV/8lzvA8RIsxgAbC143Ah8q3snMFgGLAE499dSjU7JCcRqGnpI8ZFCxoueyqZkIoyeW+yyD0AnAoXyuHyhXQY5Zx8vQ2VJ/g13qm+5+j7s3uHtDXV3dUSiWiMjgcLwEi0ZgbMHremBTP5VFRGTQOV6CxQvABDMbb2YZYD6wop/LJCIyaBwXfRbunjWz/wr8lGTo7H3uvqafiyUiMmgcF8ECwN0fAx7r73KIiAxGx0szlIiI9CMFCxER6ZGChYiI9Oi4mO7jcJjZNuC3h5l9FLC9D4tzPBiM1wyD87oH4zXD4Lzuw7nm09y9y41qAzZYHAkzW11qbpSBbDBeMwzO6x6M1wyD87r78prVDCUiIj1SsBARkR4pWJR2T38XoB8MxmuGwXndg/GaYXBed59ds/osRESkR6pZiIhIjxQsRESkRwoWBcxsjpmtNbN1ZnZzf5enXMxsrJn93MzeNLM1ZvblkH6CmT1pZm+H5xH9Xda+Zmaxmb1sZj8OrwfDNQ83sx+Y2VvhZ/5HA/26zezG8Lv9upk9ZGaVA/Gazew+M9tqZq8XpHV7nWZ2S/j/ttbMPnko51KwCMI6398G/hiYBFxhZpP6t1RlkwX+m7t/ADgHuC5c683ASnefAKwMrweaLwNvFrweDNf8D8AT7j4RmEZy/QP2us1sDHA90ODuU0hmqp7PwLzm+4E5RWklrzP8jc8HJoc8d4X/e72iYLFf5zrf7t4GdKzzPeC4+2Z3fylsN5H88xhDcr1Lw25LgUv6pYBlYmb1wKeBewuSB/o1DwU+CnwHwN3b3H0nA/y6SWbUrjKzFFBNsljagLtmd18FvFeU3N11zgWWuXuru68H1pH83+sVBYv9Sq3zPaafynLUmNk4YAbwHHCSu2+GJKAAJ/Zj0crhW8DXgHxB2kC/5tOBbcB3Q/PbvWZWwwC+bnf/HXAn8C6wGdjl7j9jAF9zke6u84j+xylY7Nerdb4HEjOrBX4I3ODuu/u7POVkZhcBW939xf4uy1GWAmYCd7v7DGAvA6P5pVuhjX4uMB44Bagxs8/2b6mOCUf0P07BYr9Btc63maVJAsWD7v5vIXmLmY0O748GtvZX+crgPOBiM9tA0sT4cTP7HgP7miH5vW509+fC6x+QBI+BfN0XAuvdfZu7twP/BpzLwL7mQt1d5xH9j1Ow2G/QrPNtZkbShv2mu3+z4K0VwIKwvQB49GiXrVzc/RZ3r3f3cSQ/2//r7p9lAF8zgLv/HthoZmeGpAuANxjY1/0ucI6ZVYff9QtI+uUG8jUX6u46VwDzzazCzMYDE4Dne3tQ3cFdwMw+RdKu3bHO9+L+LVF5mNmHgV8Cr7G//f7rJP0Wy4FTSf7g5rl7cefZcc/MZgN/4e4XmdlIBvg1m9l0kk79DPAO8DmSL4oD9rrN7G+Ay0lG/r0M/BlQywC7ZjN7CJhNMhX5FuBW4BG6uU4z++/A1SSfyw3u/nivz6VgISIiPVEzlIiI9EjBQkREeqRgISIiPVKwEBGRHilYiIhIjxQsRA6BmeXM7JWCR5/dDW1m4wpnDxU5lqT6uwAix5lmd5/e34UQOdpUsxDpA2a2wcz+p5k9Hx5/GNJPM7OVZvar8HxqSD/JzB42s1fD49xwqNjM/imsxfAzM6sK+19vZm+E4yzrp8uUQUzBQuTQVBU1Q11e8N5ud58F/G+SmQAI2w+4+1nAg8CSkL4E+IW7TyOZq2lNSJ8AfNvdJwM7gc+E9JuBGeE4XyzPpYl0T3dwixwCM9vj7rUl0jcAH3f3d8Ikjb9395Fmth0Y7e7tIX2zu48ys21Avbu3FhxjHPBkWLQGM7sJSLv7/zCzJ4A9JFM5POLue8p8qSIHUM1CpO94N9vd7VNKa8F2jv39ip8mWcnxbODFsKiPyFGjYCHSdy4veH42bD9DMsstwJXAv4ftlcC10Lku+NDuDmpmETDW3X9OsnjTcJJJ8USOGn07ETk0VWb2SsHrJ9y9Y/hshZk9R/Il7IqQdj1wn5l9lWTFus+F9C8D95jZNSQ1iGtJVnUrJQa+Z2bDSBaw+fuwNKrIUaM+C5E+EPosGtx9e3+XRaQc1AwlIiI9Us1CRER6pJqFiIj0SMFCRER6pGAhIiI9UrAQEZEeKViIiEiP/j/VUe/7a4HY+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the dataset into input features (X) and target variable (y)\n",
    "#X_train = train.drop(columns=['y', 'ID'])  # Drop target variable and non-predictive variables\n",
    "#y_train = train['y']  # Target variable\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "\n",
    "# Plot training history (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef123cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step\n",
      "Root Mean Squared Error (RMSE): 9.138978837702254\n",
      "R-squared (R²): 0.4571767277966843\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R²):\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bfb425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
