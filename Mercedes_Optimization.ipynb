{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "29fdef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4ae4cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "80d84c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "49de450b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4b93e103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b9b0866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1770</td>\n",
       "      <td>265.32</td>\n",
       "      <td>y</td>\n",
       "      <td>r</td>\n",
       "      <td>ai</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>ag</td>\n",
       "      <td>l</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>681</td>\n",
       "      <td>169.91</td>\n",
       "      <td>aa</td>\n",
       "      <td>l</td>\n",
       "      <td>ak</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2903</td>\n",
       "      <td>167.45</td>\n",
       "      <td>ai</td>\n",
       "      <td>b</td>\n",
       "      <td>ae</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>ac</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>6273</td>\n",
       "      <td>165.52</td>\n",
       "      <td>aj</td>\n",
       "      <td>v</td>\n",
       "      <td>r</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>q</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>2396</td>\n",
       "      <td>160.87</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>ab</td>\n",
       "      <td>g</td>\n",
       "      <td>p</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID       y  X0 X1  X2 X3 X4  X5 X6 X8  ...  X375  X376  X377  X378  \\\n",
       "883   1770  265.32   y  r  ai  f  d  ag  l  t  ...     0     0     0     0   \n",
       "342    681  169.91  aa  l  ak  f  d   i  c  d  ...     0     0     0     0   \n",
       "1459  2903  167.45  ai  b  ae  a  d  ac  g  m  ...     0     0     1     0   \n",
       "3133  6273  165.52  aj  v   r  c  d   q  g  a  ...     0     0     1     0   \n",
       "1203  2396  160.87   j  o  as  f  d  ab  g  p  ...     1     0     0     0   \n",
       "\n",
       "      X379  X380  X382  X383  X384  X385  \n",
       "883      0     0     0     0     0     0  \n",
       "342      0     0     0     0     0     0  \n",
       "1459     0     0     0     0     0     0  \n",
       "3133     0     0     0     0     0     0  \n",
       "1203     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"y\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6aa94853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Testing time: 100.67 seconds\n"
     ]
    }
   ],
   "source": [
    "# Average testing time (seconds)\n",
    "\n",
    "np.mean(df['y'])\n",
    "print(\"Average Testing time:\",np.round(np.mean(df['y']),2),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82287cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "126829b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1- Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65669ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c3fd8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "# Extract features and target variable from the training set\n",
    "X = df.drop(columns=['y'])\n",
    "y = df[\"y\"]\n",
    "\n",
    "# Identify categorical columns in the dataset\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Identify quantative columns in the dataset\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Split the data into training and testing sets- 80% is train, and 20% is test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create transformers for numerical and categorical columns\n",
    "\n",
    "# numerical- replace NA's with mean and scale the data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categorical- replace NA's with the most frequent value and ignore any new value in the \n",
    "# test data that has not appeared in the training set.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Create a preprocessor to apply transformers to appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Apply preprocessing steps to the data\n",
    "preprocessed_data = preprocessor.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9ea6bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE score: 3.3864122229035187\n",
      "Testing RMSE score: 8.707194823432323\n"
     ]
    }
   ],
   "source": [
    "# Initialize RF model\n",
    "rf_model = RandomForestRegressor(random_state=499)\n",
    "\n",
    "# Create a pipeline with the preprocessor and RandomForestRegressor model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', rf_model)\n",
    "])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the RF model's performance\n",
    "RMSE_train = np.sqrt(MSE(y_train, y_train_pred))\n",
    "RMSE_test = np.sqrt(MSE(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Training RMSE score: {RMSE_train}\")\n",
    "print(f\"Testing RMSE score: {RMSE_test}\")\n",
    "\n",
    "# Currently the model is overfit, will need to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6f6fe2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'regressor__max_depth': 5, 'regressor__min_samples_leaf': 3, 'regressor__min_samples_split': 16, 'regressor__n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "# using Cross-Validation to tune the hyperparameters of RF model\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [75, 100],\n",
    "    'regressor__max_depth': [5, 10],\n",
    "    'regressor__min_samples_split': [12, 16, 20],\n",
    "    'regressor__min_samples_leaf': [3,8]\n",
    "}\n",
    "\n",
    "# Create a pipeline with the preprocessor and Random Forest model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', rf_model)\n",
    "])\n",
    "\n",
    "# Instantiate GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(model,  # Use the entire pipeline here\n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [1, 10, 50, 75, 100],\n",
    "#     'regressor__max_depth': [None, 2, 5, 7, 10],\n",
    "#     'regressor__min_samples_split': [2, 5, 10, 12, 16],\n",
    "#     'regressor__min_samples_leaf': [1, 2, 3, 5, 8]\n",
    "# }\n",
    "\n",
    "# Best Parameters: {'regressor__max_depth': 5,\n",
    "#'regressor__min_samples_leaf': 3, 'regressor__min_samples_split': 16, \n",
    "#'regressor__n_estimators': 75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9d1cf9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE score: 8.037151664831006\n",
      "Testing RMSE score: 8.105639541486896\n",
      "\n",
      "Training R^2 score: 59.6%\n",
      "Testing R^2 score: 59.8%\n"
     ]
    }
   ],
   "source": [
    "best_model_RF = grid_search.best_estimator_\n",
    "\n",
    "# Tuned RF model's accuracy on train and test\n",
    "y_train_pred = best_model_RF.predict(X_train)\n",
    "y_test_pred = best_model_RF.predict(X_test)\n",
    "\n",
    "RMSE_train = np.sqrt(MSE(y_train, y_train_pred))\n",
    "RMSE_test = np.sqrt(MSE(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Training RMSE score: {RMSE_train}\")\n",
    "print(f\"Testing RMSE score: {RMSE_test}\")\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTraining R^2 score: {np.round(r2_train*100,1)}%\")\n",
    "print(f\"Testing R^2 score: {np.round(r2_test*100,1)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "509f8541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps: dict_keys(['preprocessor', 'regressor'])\n"
     ]
    }
   ],
   "source": [
    "# RF provides automatic feature selection. Now finding what are the best features!\n",
    "\n",
    "# Checking the names of steps in the Pipeline\n",
    "step_names = best_model_RF.named_steps.keys()\n",
    "print(\"Pipeline steps:\", step_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "369e209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the top 50 features that are automatically selected by RF\n",
    "\n",
    "# rf_estimator = best_model_RF.named_steps['regressor']\n",
    "\n",
    "# # Get the feature importance scores from the random forest estimator\n",
    "# feature_importances = rf_estimator.feature_importances_\n",
    "\n",
    "# # Get the feature names\n",
    "# feature_names = df.columns  \n",
    "\n",
    "# # Sort the features by importance in descending order\n",
    "# sorted_features = sorted(zip(feature_importances, feature_names), reverse=True)\n",
    "\n",
    "# # Select the top 15 features\n",
    "# top_15_features = [x[1] for x in sorted_features[:50]]\n",
    "\n",
    "# print(\"Top 15 features selected by the random forest model:\")\n",
    "# print(top_15_features)\n",
    "\n",
    "# top_15_df = df[top_15_feature_names].copy()\n",
    "# top_15_df[\"y\"] = df[\"y\"]\n",
    "\n",
    "\n",
    "# # creating model with just top 15 features\n",
    "\n",
    "\n",
    "# # Extract features and target variable from the training set\n",
    "# X = top_15_df.drop(columns=['y'])\n",
    "# y = top_15_df[\"y\"]\n",
    "\n",
    "# # Identify categorical columns in the dataset\n",
    "# categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# # Identify quantative columns in the dataset\n",
    "# numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# # Split the data into training and testing sets- 80% is train, and 20% is test data.\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# # Create transformers for numerical and categorical columns\n",
    "\n",
    "# # numerical- replace NA's with mean and scale the data\n",
    "# numerical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# # categorical- replace NA's with the most frequent value and ignore any new value in the \n",
    "# # test data that has not appeared in the training set.\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "\n",
    "# # Create a preprocessor to apply transformers to appropriate columns\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_transformer, numerical_cols),\n",
    "#         ('cat', categorical_transformer, categorical_cols)\n",
    "#     ])\n",
    "\n",
    "\n",
    "# # Apply preprocessing steps to the data\n",
    "# preprocessed_data = preprocessor.fit_transform(X)\n",
    "\n",
    "\n",
    "# # using Cross-Validation to tune the hyperparameters of RF model\n",
    "\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [75, 100],\n",
    "#     'regressor__max_depth': [5, 10],\n",
    "#     'regressor__min_samples_split': [12, 16, 20],\n",
    "#     'regressor__min_samples_leaf': [3,8]\n",
    "# }\n",
    "\n",
    "# # Create a pipeline with the preprocessor and Random Forest model\n",
    "# model = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', rf_model)\n",
    "# ])\n",
    "\n",
    "# # Instantiate GridSearchCV with the pipeline and parameter grid\n",
    "# grid_search = GridSearchCV(model,  # Use the entire pipeline here\n",
    "#                            param_grid=param_grid, \n",
    "#                            cv=5, \n",
    "#                            scoring='neg_mean_squared_error', \n",
    "#                            n_jobs=-1)\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and best score found\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# # best model\n",
    "# best_model_RF = grid_search.best_estimator_\n",
    "\n",
    "# # Tuned RF model's accuracy on train and test\n",
    "# y_train_pred = best_model_RF.predict(X_train)\n",
    "# y_test_pred = best_model_RF.predict(X_test)\n",
    "\n",
    "# RMSE_train = np.sqrt(MSE(y_train, y_train_pred))\n",
    "# RMSE_test = np.sqrt(MSE(y_test, y_test_pred))\n",
    "\n",
    "# print(f\"Training RMSE score: {RMSE_train}\")\n",
    "# print(f\"Testing RMSE score: {RMSE_test}\")\n",
    "\n",
    "# r2_train = r2_score(y_train, y_train_pred)\n",
    "# r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# print(f\"\\nTraining R^2 score: {np.round(r2_train*100,1)}%\")\n",
    "# print(f\"Testing R^2 score: {np.round(r2_test*100,1)}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3f0ba351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6700f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7a6d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the result in csv\n",
    "\n",
    "# test_df = pd.read_csv(\"test.csv\")\n",
    "# y_test_pred = best_model_RF.predict(test_df)\n",
    "\n",
    "# submission_file = pd.DataFrame({\n",
    "#     'ID': test_df['ID'],\n",
    "#     'y': y_test_pred\n",
    "# })\n",
    "\n",
    "# submission_file.to_csv('RF_Submission_All_Features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e165a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b9bcdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis (PCA) to reduce dimensionality\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b237ae20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3305f71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create scaler: scaler\n",
    "scaler_pca = StandardScaler()\n",
    "\n",
    "# Create a PCA instance: pca\n",
    "pca = PCA()\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline_pca = make_pipeline(scaler_pca, pca)\n",
    "\n",
    "# Fit the pipeline to 'samples'\n",
    "pipeline_pca.fit(preprocessed_data)\n",
    "\n",
    "# # Plot the explained variances\n",
    "# features = range(pca.n_components_)\n",
    "# plt.bar(features, pca.explained_variance_)\n",
    "# plt.xlabel('PCA feature')\n",
    "# plt.ylabel('variance')\n",
    "# plt.xticks(features)\n",
    "# plt.show()\n",
    "\n",
    "# Plot the explained variances\n",
    "features = range(min(20, pca.n_components_))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(features, pca.explained_variance_[:len(features)])\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('Variance')\n",
    "plt.xticks(features, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# How to find which feature is which x-variable!?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6eca58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 15)\n"
     ]
    }
   ],
   "source": [
    "# find top 15 features using PCA\n",
    "\n",
    "pca = PCA(n_components=15)\n",
    "\n",
    "# Fit the PCA instance to the preprocessed_data\n",
    "pca.fit(preprocessed_data)\n",
    "\n",
    "# Transform preprocessed_data: pca_features\n",
    "pca_features_15 = pca.transform(preprocessed_data)\n",
    "\n",
    "# Print the shape of pca_features\n",
    "print(pca_features_15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d0eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6f81711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 feature names: ['X348', 'X80', 'X126', 'X264', 'X111', 'X198', 'X128', 'X130', 'X147', 'X134', 'X222', 'X113', 'X48', 'X66', 'X179']\n"
     ]
    }
   ],
   "source": [
    "# find top 15 features using PCA and get the original names of features\n",
    "\n",
    "# Get the column names after preprocessing df\n",
    "transformed_numerical_cols_15 = preprocessor.transformers_[0][2]\n",
    "\n",
    "# Getting dummy variables from categorical columns\n",
    "transformed_categorical_cols_15 = preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Concatenate the transformed numerical and categorical column names\n",
    "transformed_cols_15 = list(transformed_numerical_cols_15) + list(transformed_categorical_cols_15)\n",
    "\n",
    "# Fit the PCA instance to the preprocessed_data\n",
    "pca.fit(preprocessed_data)\n",
    "\n",
    "# Get the loadings of the principal components\n",
    "pca_components_15 = pca.components_\n",
    "\n",
    "# Get the indices of the top 15 features based on the pca_components of the first principal component\n",
    "# select 15 highest loadings\n",
    "top_15_indices = np.argsort(np.abs(pca_components_15[0]))[::-1][:15]\n",
    "\n",
    "# Get the names of the top 15 features\n",
    "top_15_feature_names = [transformed_cols_15[i] for i in top_15_indices]\n",
    "print(\"Top 15 feature names:\", top_15_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86ac86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e9e69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dimensionally reduced df- just using top 15 features!\n",
    "# re-create RF model\n",
    "\n",
    "df_reduced = df.loc[:, top_15_feature_names]\n",
    "df_reduced[\"y\"] = df[\"y\"]\n",
    "\n",
    "# Extract features and target variable from the training set\n",
    "X = df_reduced.drop(columns=['y'])\n",
    "y = df_reduced[\"y\"]\n",
    "\n",
    "# Identify categorical columns in the dataset\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Identify quantative columns in the dataset\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Split the data into training and testing sets- 80% is train, and 20% is test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create transformers for numerical and categorical columns\n",
    "\n",
    "# numerical- replace NA's with mean and scale the data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categorical- replace NA's with the most frequent value and ignore any new value in the \n",
    "# test data that has not appeared in the training set.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Create a preprocessor to apply transformers to appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Apply preprocessing steps to the data\n",
    "preprocessed_data = preprocessor.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03d4a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE score: 12.204540169189926\n",
      "Testing RMSE score: 12.47707661450852\n"
     ]
    }
   ],
   "source": [
    "# Initialize RF model\n",
    "rf_model = RandomForestRegressor(random_state=499)\n",
    "\n",
    "# Create a pipeline with the preprocessor and RandomForestRegressor model\n",
    "reduced_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', rf_model)\n",
    "])\n",
    "\n",
    "# Fit the model to the training data\n",
    "reduced_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = reduced_model.predict(X_train)\n",
    "y_test_pred = reduced_model.predict(X_test)\n",
    "\n",
    "# Evaluate the RF model's performance\n",
    "RMSE_train = np.sqrt(MSE(y_train, y_train_pred))\n",
    "RMSE_test = np.sqrt(MSE(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Training RMSE score: {RMSE_train}\")\n",
    "print(f\"Testing RMSE score: {RMSE_test}\")\n",
    "\n",
    "# Currently the model is overfit, will need to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bee56046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'regressor__max_depth': 2, 'regressor__min_samples_leaf': 8, 'regressor__min_samples_split': 5, 'regressor__n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "# using Cross-Validation to tune the hyperparameters of RF model\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50,75,100],\n",
    "    'regressor__max_depth': [2,5,7],\n",
    "    'regressor__min_samples_split': [5,8,12,20],\n",
    "    'regressor__min_samples_leaf': [3,8,10]\n",
    "}\n",
    "\n",
    "# Create a pipeline with the preprocessor and Random Forest model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', rf_model)\n",
    "])\n",
    "\n",
    "# Instantiate GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(model,  # Use the entire pipeline here\n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b16690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE score: 12.25017189808907\n",
      "Testing RMSE score: 12.456379230289317\n",
      "\n",
      "Training R^2 score: 6.2%\n",
      "Testing R^2 score: 5.0%\n"
     ]
    }
   ],
   "source": [
    "pca_model_RF = grid_search.best_estimator_\n",
    "\n",
    "# Tuned RF model's accuracy on train and test\n",
    "y_train_pred = pca_model_RF.predict(X_train)\n",
    "y_test_pred = pca_model_RF.predict(X_test)\n",
    "\n",
    "RMSE_train = np.sqrt(MSE(y_train, y_train_pred))\n",
    "RMSE_test = np.sqrt(MSE(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Training RMSE score: {RMSE_train}\")\n",
    "print(f\"Testing RMSE score: {RMSE_test}\")\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTraining R^2 score: {np.round(r2_train*100,1)}%\")\n",
    "print(f\"Testing R^2 score: {np.round(r2_test*100,1)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71a9678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the result in csv\n",
    "\n",
    "# test_df = pd.read_csv(\"test.csv\")\n",
    "# y_test_pred = pca_model_RF.predict(test_df)\n",
    "\n",
    "# submission_file = pd.DataFrame({\n",
    "#     'ID': test_df['ID'],\n",
    "#     'y': y_test_pred\n",
    "# })\n",
    "\n",
    "# submission_file.to_csv('RF_Submission_15_Features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35109395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion so far:\n",
    "\n",
    "# with all the features: ~8 seconds RMSE\n",
    "# with only 15 features: ~12 seconds RMSE\n",
    "\n",
    "# Next steps- use another predictive model and another method to reduce dimensions\n",
    "# can also create some neural nets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd99d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941756fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "12696d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the data again\n",
    "\n",
    "# Extract features and target variable from the training set\n",
    "X = df.drop(columns=['y'])\n",
    "y = df[\"y\"]\n",
    "\n",
    "# Identify categorical columns in the dataset\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Identify quantative columns in the dataset\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Split the data into training and testing sets- 80% is train, and 20% is test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create transformers for numerical and categorical columns\n",
    "\n",
    "# numerical- replace NA's with mean and scale the data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categorical- replace NA's with the most frequent value and ignore any new value in the \n",
    "# test data that has not appeared in the training set.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Create a preprocessor to apply transformers to appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Apply preprocessing steps to the data\n",
    "preprocessed_data = preprocessor.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cdfa2ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 53)\n"
     ]
    }
   ],
   "source": [
    "# Try getting 70% of variation- will need 82 features!\n",
    "\n",
    "pca = PCA(0.70)\n",
    "\n",
    "# Fit the PCA instance to the preprocessed_data\n",
    "pca.fit(preprocessed_data)\n",
    "\n",
    "# Transform preprocessed_data: pca_features\n",
    "pca_features = pca.transform(preprocessed_data)\n",
    "\n",
    "# Print the shape of pca_features\n",
    "print(pca_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f4970233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 53 feature names: ['X348', 'X80', 'X126', 'X264', 'X111', 'X198', 'X128', 'X130', 'X48', 'X222', 'X147', 'X134', 'X113', 'X66', 'X179', 'X265', 'X101', 'X170', 'X98', 'X238', 'X189', 'X304', 'X75', 'X306', 'X61', 'X120', 'X52', 'X228', 'X229', 'X208', 'X368', 'X209', 'X103', 'X100', 'X144', 'X49', 'X129', 'X31', 'X35', 'X37', 'X68', 'X255', 'X334', 'X362', 'X337', 'X114', 'X50', 'X244', 'X71', 'X84', 'X27', 'X241', 'X218']\n"
     ]
    }
   ],
   "source": [
    "# find top 53 features using PCA and get the original names of features\n",
    "\n",
    "# Get the column names after preprocessing df\n",
    "transformed_numerical_cols = preprocessor.transformers_[0][2]\n",
    "transformed_categorical_cols = preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Concatenate the transformed numerical and categorical column names\n",
    "transformed_cols = list(transformed_numerical_cols) + list(transformed_categorical_cols)\n",
    "\n",
    "# Fit the PCA instance to the preprocessed_data\n",
    "pca.fit(preprocessed_data)\n",
    "\n",
    "# Get the loadings of the principal components\n",
    "pca_components = pca.components_\n",
    "\n",
    "# Get the indices of the top 53 features based on the pca_components of the first principal component\n",
    "top_53_indices = np.argsort(np.abs(pca_components[0]))[::-1][:53]\n",
    "\n",
    "# Get the names of the top 53 features\n",
    "top_53_feature_names = [transformed_cols[i] for i in top_53_indices]\n",
    "print(\"Top 53 feature names:\", top_53_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5cc0ea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE score: 9.7083435400749\n",
      "Testing RMSE score: 11.352107574562805\n",
      "\n",
      "Training R^2 score: 41.1%\n",
      "Testing R^2 score: 21.1%\n"
     ]
    }
   ],
   "source": [
    "# making model from 53 features- \n",
    "\n",
    "# Using dimensionally reduced df- just using top 15 features!\n",
    "# re-create RF model\n",
    "\n",
    "df_reduced = df.loc[:, top_53_feature_names]\n",
    "df_reduced[\"y\"] = df[\"y\"]\n",
    "\n",
    "# Extract features and target variable from the training set\n",
    "X = df_reduced.drop(columns=['y'])\n",
    "y = df_reduced[\"y\"]\n",
    "\n",
    "# Identify categorical columns in the dataset\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Identify quantative columns in the dataset\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Split the data into training and testing sets- 80% is train, and 20% is test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create transformers for numerical and categorical columns\n",
    "\n",
    "# numerical- replace NA's with mean and scale the data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categorical- replace NA's with the most frequent value and ignore any new value in the \n",
    "# test data that has not appeared in the training set.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Create a preprocessor to apply transformers to appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Apply preprocessing steps to the data\n",
    "preprocessed_data = preprocessor.fit_transform(X)\n",
    "\n",
    "# Initialize RF model\n",
    "rf_model = RandomForestRegressor(random_state=499)\n",
    "\n",
    "# Create a pipeline with the preprocessor and RandomForestRegressor model\n",
    "reduced_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', rf_model)\n",
    "])\n",
    "\n",
    "# Fit the model to the training data\n",
    "reduced_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = reduced_model.predict(X_train)\n",
    "y_test_pred = reduced_model.predict(X_test)\n",
    "\n",
    "# Evaluate the RF model's performance\n",
    "RMSE_train = np.sqrt(MSE(y_train, y_train_pred))\n",
    "RMSE_test = np.sqrt(MSE(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Training RMSE score: {RMSE_train}\")\n",
    "print(f\"Testing RMSE score: {RMSE_test}\")\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTraining R^2 score: {np.round(r2_train*100,1)}%\")\n",
    "print(f\"Testing R^2 score: {np.round(r2_test*100,1)}%\")\n",
    "\n",
    "# 53 features capture 70% of variation!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25996e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3cf45a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward elimination for feature selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbff10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8133337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb30c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba7d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
